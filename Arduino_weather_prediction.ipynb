{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1apkerEC0HXyNLDXuKket"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2KRSGXJJu4Fk","executionInfo":{"status":"ok","timestamp":1764945156115,"user_tz":0,"elapsed":2068,"user":{"displayName":"Marcelina Marjankowska","userId":"02060429220160125721"}}},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["import kagglehub\n","import os\n","import csv\n","import numpy as np\n","\n","path = kagglehub.dataset_download(\"sujithmandala/simple-rainfall-classification-dataset\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2dIg8SQvC9a","executionInfo":{"status":"ok","timestamp":1764945162231,"user_tz":0,"elapsed":6120,"user":{"displayName":"Marcelina Marjankowska","userId":"02060429220160125721"}},"outputId":"ba8a71ff-edb2-4c60-d59a-7d4c6c26ad12"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/sujithmandala/simple-rainfall-classification-dataset?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 804/804 [00:00<00:00, 1.63MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n","Path to dataset files: /root/.cache/kagglehub/datasets/sujithmandala/simple-rainfall-classification-dataset/versions/1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import os\n","import csv\n","import numpy as np\n","\n","# --- File path ---\n","train_file = os.path.join(path, \"rainfall.csv\")\n","\n","# --- 1. Load CSV into NumPy arrays (skip header) ---\n","data_list = []\n","label_list = []\n","with open(train_file, \"r\") as f:\n","    reader = csv.reader(f)\n","    header = next(reader)  # skip header\n","    for row in reader:\n","        # take columns 2:4 for features and last column for label\n","        data_list.append(row[2:4])\n","        label_list.append(row[-1])\n","data_list.pop()\n","label_list.pop()\n","\n","# Convert to NumPy arrays\n","data = np.array(data_list, dtype=float)  # converts strings to floats\n","labels = np.array(label_list)\n","\n","# --- 2. Remove rows with missing values ---\n","mask = np.all(data != \"\", axis=1) & (labels != \"\")\n","data = data[mask]\n","labels = labels[mask]\n","\n","# --- 3. Convert labels to binary (0/1) ---\n","labels_bin = np.array([1 if l == \"Rainy\" else 0 for l in labels])\n","\n","# --- 4. Split into train/test ---\n","test_size = 6\n","X_train = data[:-test_size]\n","y_train = labels_bin[:-test_size]\n","\n","X_test = data[-test_size:]\n","y_test = labels_bin[-test_size:]\n","\n","# --- 5. Print shapes and samples ---\n","print(\"Train samples:\", X_train.shape[0], \"Train features:\", X_train.shape[1])\n","print(\"Test samples:\", X_test.shape[0], \"Test features:\", X_test.shape[1])\n","\n","print(\"\\nExample X_train:\", X_train[:3])\n","print(\"Example y_train:\", y_train[:3])\n","\n","print(\"\\nExample X_test:\", X_test)\n","print(\"Example y_test:\", y_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKKKhfzNvI4m","executionInfo":{"status":"ok","timestamp":1764945162247,"user_tz":0,"elapsed":13,"user":{"displayName":"Marcelina Marjankowska","userId":"02060429220160125721"}},"outputId":"c059435a-bb4d-4336-a6df-d5b3f2cd7eb4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Train samples: 47 Train features: 2\n","Test samples: 6 Test features: 2\n","\n","Example X_train: [[15.2 78. ]\n"," [17.8 65. ]\n"," [20.1 52. ]]\n","Example y_train: [1 1 0]\n","\n","Example X_test: [[17.4 75. ]\n"," [14.1 89. ]\n"," [15.9 83. ]\n"," [18.6 71. ]\n"," [21.3 55. ]\n"," [16.8 77. ]]\n","Example y_test: [1 1 1 1 0 1]\n"]}]},{"cell_type":"code","source":["# # --- 1. Remove header row ---\n","# data = train_data[1:]       # skip [\"temperature\",\"humidity\"]\n","# labels = train_label[1:]    # skip [\"weather_condition\"]\n","\n","# # --- 2. Remove empty rows (e.g. ['', ''] or '') ---\n","# clean_data = []\n","# clean_labels = []\n","\n","# for row, label in zip(data, labels):\n","#     # skip rows containing empty strings\n","#     if \"\" in row or label == \"\":\n","#         continue\n","\n","#     # convert input features to floats\n","#     features = [float(row[0]), float(row[1])]\n","\n","#     clean_data.append(features)\n","#     clean_labels.append(label)\n","\n","# # --- 3. Split into train (all but last 6) and test (last 6) ---\n","# test_size = 6\n","\n","# X_train = clean_data[:-test_size]\n","# y_train = clean_labels[:-test_size]\n","\n","# X_test = clean_data[-test_size:]\n","# y_test = clean_labels[-test_size:]\n","\n","# # --- 4. Print shapes and samples ---\n","# print(\"Train samples:\", len(X_train))\n","# print(\"Test samples:\", len(X_test))\n","\n","# print(\"\\nExample X_train:\", X_train[:3])\n","# print(\"Example y_train:\", y_train[:3])\n","\n","# print(\"\\nExample X_test:\", X_test)\n","# print(\"Example y_test:\", y_test)\n"],"metadata":{"id":"XeptK-0jvrxP","executionInfo":{"status":"ok","timestamp":1764945162274,"user_tz":0,"elapsed":24,"user":{"displayName":"Marcelina Marjankowska","userId":"02060429220160125721"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","\n","\n","import os\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import math"],"metadata":{"id":"misb4Vg9xgIa","executionInfo":{"status":"ok","timestamp":1764945173645,"user_tz":0,"elapsed":11375,"user":{"displayName":"Marcelina Marjankowska","userId":"02060429220160125721"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","# Binary classification model\n","model = keras.Sequential()\n","\n","# Input layer: 2 features\n","model.add(keras.layers.Dense(16, activation='relu', input_shape=(2,)))\n","\n","# Hidden layer\n","model.add(keras.layers.Dense(16, activation='relu'))\n","\n","# Output layer: 1 neuron with sigmoid for binary classification\n","model.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","# Compile model\n","model.compile(\n","    optimizer='adam',\n","    loss='binary_crossentropy',  # binary classification\n","    metrics=['accuracy']\n",")\n","\n","# Summary\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"cHKgGoFPx14-","executionInfo":{"status":"ok","timestamp":1764945173872,"user_tz":0,"elapsed":222,"user":{"displayName":"Marcelina Marjankowska","userId":"02060429220160125721"}},"outputId":"1967cf83-2bc9-4d6b-c885-b511c898d324"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m48\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m337\u001b[0m (1.32 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">337</span> (1.32 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m337\u001b[0m (1.32 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">337</span> (1.32 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["\n","history = model.fit(X_train, y_train, epochs=150, batch_size=64,\n","                    validation_data=(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWSEnEMJyUm1","executionInfo":{"status":"ok","timestamp":1764945190676,"user_tz":0,"elapsed":16806,"user":{"displayName":"Marcelina Marjankowska","userId":"02060429220160125721"}},"outputId":"846a809d-8c67-4163-caa0-b5a53c524320"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7872 - loss: 1.8980 - val_accuracy: 0.8333 - val_loss: 1.5433\n","Epoch 2/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7872 - loss: 1.8585 - val_accuracy: 0.8333 - val_loss: 1.5101\n","Epoch 3/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 1.8194 - val_accuracy: 0.8333 - val_loss: 1.4774\n","Epoch 4/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 1.7810 - val_accuracy: 0.8333 - val_loss: 1.4451\n","Epoch 5/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7872 - loss: 1.7430 - val_accuracy: 0.8333 - val_loss: 1.4132\n","Epoch 6/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7872 - loss: 1.7057 - val_accuracy: 0.8333 - val_loss: 1.3819\n","Epoch 7/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 1.6688 - val_accuracy: 0.8333 - val_loss: 1.3510\n","Epoch 8/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7872 - loss: 1.6326 - val_accuracy: 0.8333 - val_loss: 1.3205\n","Epoch 9/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7872 - loss: 1.5968 - val_accuracy: 0.8333 - val_loss: 1.2906\n","Epoch 10/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7872 - loss: 1.5616 - val_accuracy: 0.8333 - val_loss: 1.2610\n","Epoch 11/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 1.5268 - val_accuracy: 0.8333 - val_loss: 1.2319\n","Epoch 12/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7872 - loss: 1.4926 - val_accuracy: 0.8333 - val_loss: 1.2033\n","Epoch 13/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7872 - loss: 1.4589 - val_accuracy: 0.8333 - val_loss: 1.1750\n","Epoch 14/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 1.4256 - val_accuracy: 0.8333 - val_loss: 1.1471\n","Epoch 15/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 1.3929 - val_accuracy: 0.8333 - val_loss: 1.1196\n","Epoch 16/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 1.3606 - val_accuracy: 0.8333 - val_loss: 1.0925\n","Epoch 17/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 1.3290 - val_accuracy: 0.8333 - val_loss: 1.0658\n","Epoch 18/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 1.2979 - val_accuracy: 0.8333 - val_loss: 1.0395\n","Epoch 19/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7872 - loss: 1.2674 - val_accuracy: 0.8333 - val_loss: 1.0136\n","Epoch 20/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7872 - loss: 1.2375 - val_accuracy: 0.8333 - val_loss: 0.9880\n","Epoch 21/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7872 - loss: 1.2081 - val_accuracy: 0.8333 - val_loss: 0.9629\n","Epoch 22/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7872 - loss: 1.1791 - val_accuracy: 0.8333 - val_loss: 0.9381\n","Epoch 23/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7872 - loss: 1.1505 - val_accuracy: 0.8333 - val_loss: 0.9137\n","Epoch 24/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7872 - loss: 1.1223 - val_accuracy: 0.8333 - val_loss: 0.8896\n","Epoch 25/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7872 - loss: 1.0946 - val_accuracy: 0.8333 - val_loss: 0.8659\n","Epoch 26/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7872 - loss: 1.0672 - val_accuracy: 0.8333 - val_loss: 0.8426\n","Epoch 27/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7872 - loss: 1.0402 - val_accuracy: 0.8333 - val_loss: 0.8195\n","Epoch 28/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7872 - loss: 1.0135 - val_accuracy: 0.8333 - val_loss: 0.7968\n","Epoch 29/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7872 - loss: 0.9873 - val_accuracy: 0.8333 - val_loss: 0.7744\n","Epoch 30/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.9614 - val_accuracy: 0.8333 - val_loss: 0.7529\n","Epoch 31/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7872 - loss: 0.9360 - val_accuracy: 0.8333 - val_loss: 0.7331\n","Epoch 32/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.9112 - val_accuracy: 0.8333 - val_loss: 0.7135\n","Epoch 33/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.8867 - val_accuracy: 0.8333 - val_loss: 0.6942\n","Epoch 34/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.8627 - val_accuracy: 0.8333 - val_loss: 0.6752\n","Epoch 35/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7872 - loss: 0.8390 - val_accuracy: 0.8333 - val_loss: 0.6565\n","Epoch 36/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.8157 - val_accuracy: 0.8333 - val_loss: 0.6380\n","Epoch 37/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.7929 - val_accuracy: 0.8333 - val_loss: 0.6198\n","Epoch 38/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.7706 - val_accuracy: 0.8333 - val_loss: 0.6030\n","Epoch 39/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.7489 - val_accuracy: 0.8333 - val_loss: 0.5871\n","Epoch 40/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.7277 - val_accuracy: 0.8333 - val_loss: 0.5714\n","Epoch 41/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7872 - loss: 0.7071 - val_accuracy: 0.8333 - val_loss: 0.5560\n","Epoch 42/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7872 - loss: 0.6869 - val_accuracy: 0.8333 - val_loss: 0.5408\n","Epoch 43/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.6672 - val_accuracy: 0.8333 - val_loss: 0.5259\n","Epoch 44/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7872 - loss: 0.6480 - val_accuracy: 0.8333 - val_loss: 0.5114\n","Epoch 45/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7872 - loss: 0.6293 - val_accuracy: 0.8333 - val_loss: 0.4973\n","Epoch 46/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7872 - loss: 0.6111 - val_accuracy: 0.8333 - val_loss: 0.4834\n","Epoch 47/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7872 - loss: 0.5939 - val_accuracy: 0.8333 - val_loss: 0.4699\n","Epoch 48/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.5775 - val_accuracy: 0.8333 - val_loss: 0.4567\n","Epoch 49/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.5619 - val_accuracy: 0.8333 - val_loss: 0.4440\n","Epoch 50/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7872 - loss: 0.5471 - val_accuracy: 0.8333 - val_loss: 0.4315\n","Epoch 51/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7872 - loss: 0.5327 - val_accuracy: 0.8333 - val_loss: 0.4195\n","Epoch 52/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7872 - loss: 0.5189 - val_accuracy: 0.8333 - val_loss: 0.4079\n","Epoch 53/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.5056 - val_accuracy: 0.8333 - val_loss: 0.3967\n","Epoch 54/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7872 - loss: 0.4927 - val_accuracy: 0.8333 - val_loss: 0.3860\n","Epoch 55/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7872 - loss: 0.4803 - val_accuracy: 0.8333 - val_loss: 0.3757\n","Epoch 56/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7872 - loss: 0.4684 - val_accuracy: 0.8333 - val_loss: 0.3659\n","Epoch 57/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7872 - loss: 0.4568 - val_accuracy: 0.8333 - val_loss: 0.3565\n","Epoch 58/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7872 - loss: 0.4463 - val_accuracy: 0.8333 - val_loss: 0.3476\n","Epoch 59/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.4363 - val_accuracy: 0.8333 - val_loss: 0.3392\n","Epoch 60/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7872 - loss: 0.4266 - val_accuracy: 0.8333 - val_loss: 0.3312\n","Epoch 61/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.4175 - val_accuracy: 0.8333 - val_loss: 0.3235\n","Epoch 62/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7872 - loss: 0.4087 - val_accuracy: 0.8333 - val_loss: 0.3163\n","Epoch 63/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.4004 - val_accuracy: 0.8333 - val_loss: 0.3130\n","Epoch 64/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7872 - loss: 0.3929 - val_accuracy: 0.8333 - val_loss: 0.3100\n","Epoch 65/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7872 - loss: 0.3860 - val_accuracy: 0.8333 - val_loss: 0.3073\n","Epoch 66/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.3801 - val_accuracy: 0.8333 - val_loss: 0.3048\n","Epoch 67/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7872 - loss: 0.3745 - val_accuracy: 0.8333 - val_loss: 0.3025\n","Epoch 68/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7872 - loss: 0.3701 - val_accuracy: 0.8333 - val_loss: 0.3004\n","Epoch 69/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.3662 - val_accuracy: 0.8333 - val_loss: 0.2983\n","Epoch 70/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 0.3627 - val_accuracy: 0.8333 - val_loss: 0.2965\n","Epoch 71/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7872 - loss: 0.3596 - val_accuracy: 0.8333 - val_loss: 0.2946\n","Epoch 72/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7872 - loss: 0.3567 - val_accuracy: 0.8333 - val_loss: 0.2929\n","Epoch 73/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.3541 - val_accuracy: 0.8333 - val_loss: 0.2913\n","Epoch 74/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 0.3515 - val_accuracy: 0.8333 - val_loss: 0.2897\n","Epoch 75/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.3490 - val_accuracy: 0.8333 - val_loss: 0.2883\n","Epoch 76/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7872 - loss: 0.3466 - val_accuracy: 0.8333 - val_loss: 0.2868\n","Epoch 77/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7872 - loss: 0.3444 - val_accuracy: 0.8333 - val_loss: 0.2855\n","Epoch 78/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7872 - loss: 0.3421 - val_accuracy: 0.8333 - val_loss: 0.2841\n","Epoch 79/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.3399 - val_accuracy: 0.8333 - val_loss: 0.2827\n","Epoch 80/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7872 - loss: 0.3377 - val_accuracy: 0.8333 - val_loss: 0.2814\n","Epoch 81/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7872 - loss: 0.3355 - val_accuracy: 0.8333 - val_loss: 0.2801\n","Epoch 82/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 0.3334 - val_accuracy: 0.8333 - val_loss: 0.2789\n","Epoch 83/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.3312 - val_accuracy: 0.8333 - val_loss: 0.2778\n","Epoch 84/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.3292 - val_accuracy: 0.8333 - val_loss: 0.2767\n","Epoch 85/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7872 - loss: 0.3272 - val_accuracy: 0.8333 - val_loss: 0.2755\n","Epoch 86/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.3252 - val_accuracy: 0.8333 - val_loss: 0.2744\n","Epoch 87/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7872 - loss: 0.3232 - val_accuracy: 0.8333 - val_loss: 0.2733\n","Epoch 88/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7872 - loss: 0.3213 - val_accuracy: 0.8333 - val_loss: 0.2723\n","Epoch 89/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7872 - loss: 0.3196 - val_accuracy: 0.8333 - val_loss: 0.2713\n","Epoch 90/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7872 - loss: 0.3180 - val_accuracy: 0.8333 - val_loss: 0.2703\n","Epoch 91/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7872 - loss: 0.3166 - val_accuracy: 0.8333 - val_loss: 0.2693\n","Epoch 92/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7872 - loss: 0.3152 - val_accuracy: 0.8333 - val_loss: 0.2683\n","Epoch 93/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7872 - loss: 0.3138 - val_accuracy: 0.8333 - val_loss: 0.2673\n","Epoch 94/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7872 - loss: 0.3124 - val_accuracy: 0.8333 - val_loss: 0.2663\n","Epoch 95/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7872 - loss: 0.3110 - val_accuracy: 0.8333 - val_loss: 0.2654\n","Epoch 96/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.7872 - loss: 0.3097 - val_accuracy: 0.8333 - val_loss: 0.2644\n","Epoch 97/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7872 - loss: 0.3083 - val_accuracy: 0.8333 - val_loss: 0.2633\n","Epoch 98/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7872 - loss: 0.3070 - val_accuracy: 0.8333 - val_loss: 0.2624\n","Epoch 99/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7872 - loss: 0.3060 - val_accuracy: 0.8333 - val_loss: 0.2615\n","Epoch 100/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7872 - loss: 0.3049 - val_accuracy: 0.8333 - val_loss: 0.2607\n","Epoch 101/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7872 - loss: 0.3039 - val_accuracy: 0.8333 - val_loss: 0.2599\n","Epoch 102/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7872 - loss: 0.3028 - val_accuracy: 0.8333 - val_loss: 0.2592\n","Epoch 103/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7872 - loss: 0.3016 - val_accuracy: 0.8333 - val_loss: 0.2586\n","Epoch 104/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.3004 - val_accuracy: 0.8333 - val_loss: 0.2580\n","Epoch 105/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 0.2991 - val_accuracy: 0.8333 - val_loss: 0.2574\n","Epoch 106/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.2980 - val_accuracy: 0.8333 - val_loss: 0.2568\n","Epoch 107/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7872 - loss: 0.2968 - val_accuracy: 0.8333 - val_loss: 0.2562\n","Epoch 108/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7872 - loss: 0.2958 - val_accuracy: 0.8333 - val_loss: 0.2554\n","Epoch 109/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7872 - loss: 0.2947 - val_accuracy: 0.8333 - val_loss: 0.2546\n","Epoch 110/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.2937 - val_accuracy: 0.8333 - val_loss: 0.2537\n","Epoch 111/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.2926 - val_accuracy: 0.8333 - val_loss: 0.2527\n","Epoch 112/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7872 - loss: 0.2915 - val_accuracy: 0.8333 - val_loss: 0.2515\n","Epoch 113/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.2904 - val_accuracy: 0.8333 - val_loss: 0.2503\n","Epoch 114/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7872 - loss: 0.2892 - val_accuracy: 0.8333 - val_loss: 0.2491\n","Epoch 115/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 0.2881 - val_accuracy: 0.8333 - val_loss: 0.2479\n","Epoch 116/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.2870 - val_accuracy: 0.8333 - val_loss: 0.2467\n","Epoch 117/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.2859 - val_accuracy: 0.8333 - val_loss: 0.2455\n","Epoch 118/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7872 - loss: 0.2849 - val_accuracy: 0.8333 - val_loss: 0.2443\n","Epoch 119/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7872 - loss: 0.2838 - val_accuracy: 0.8333 - val_loss: 0.2432\n","Epoch 120/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.2827 - val_accuracy: 0.8333 - val_loss: 0.2421\n","Epoch 121/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.2816 - val_accuracy: 0.8333 - val_loss: 0.2411\n","Epoch 122/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.2805 - val_accuracy: 0.8333 - val_loss: 0.2401\n","Epoch 123/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.2794 - val_accuracy: 0.8333 - val_loss: 0.2390\n","Epoch 124/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7872 - loss: 0.2784 - val_accuracy: 0.8333 - val_loss: 0.2381\n","Epoch 125/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.2774 - val_accuracy: 0.8333 - val_loss: 0.2372\n","Epoch 126/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7872 - loss: 0.2764 - val_accuracy: 0.8333 - val_loss: 0.2364\n","Epoch 127/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7872 - loss: 0.2754 - val_accuracy: 0.8333 - val_loss: 0.2356\n","Epoch 128/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7872 - loss: 0.2744 - val_accuracy: 0.8333 - val_loss: 0.2348\n","Epoch 129/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.2734 - val_accuracy: 0.8333 - val_loss: 0.2341\n","Epoch 130/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 0.2724 - val_accuracy: 0.8333 - val_loss: 0.2333\n","Epoch 131/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.2714 - val_accuracy: 0.8333 - val_loss: 0.2325\n","Epoch 132/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.2703 - val_accuracy: 0.8333 - val_loss: 0.2318\n","Epoch 133/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 0.2693 - val_accuracy: 0.8333 - val_loss: 0.2310\n","Epoch 134/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7872 - loss: 0.2682 - val_accuracy: 0.8333 - val_loss: 0.2303\n","Epoch 135/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7872 - loss: 0.2672 - val_accuracy: 0.8333 - val_loss: 0.2297\n","Epoch 136/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7872 - loss: 0.2662 - val_accuracy: 0.8333 - val_loss: 0.2290\n","Epoch 137/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7872 - loss: 0.2652 - val_accuracy: 0.8333 - val_loss: 0.2283\n","Epoch 138/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7872 - loss: 0.2641 - val_accuracy: 0.8333 - val_loss: 0.2275\n","Epoch 139/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7872 - loss: 0.2631 - val_accuracy: 0.8333 - val_loss: 0.2267\n","Epoch 140/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7872 - loss: 0.2622 - val_accuracy: 0.8333 - val_loss: 0.2259\n","Epoch 141/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7872 - loss: 0.2612 - val_accuracy: 0.8333 - val_loss: 0.2251\n","Epoch 142/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.2602 - val_accuracy: 0.8333 - val_loss: 0.2242\n","Epoch 143/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7872 - loss: 0.2593 - val_accuracy: 0.8333 - val_loss: 0.2234\n","Epoch 144/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.2583 - val_accuracy: 0.8333 - val_loss: 0.2226\n","Epoch 145/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7872 - loss: 0.2573 - val_accuracy: 0.8333 - val_loss: 0.2218\n","Epoch 146/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7872 - loss: 0.2564 - val_accuracy: 0.8333 - val_loss: 0.2210\n","Epoch 147/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7872 - loss: 0.2555 - val_accuracy: 0.8333 - val_loss: 0.2202\n","Epoch 148/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7872 - loss: 0.2545 - val_accuracy: 0.8333 - val_loss: 0.2194\n","Epoch 149/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7872 - loss: 0.2536 - val_accuracy: 0.8333 - val_loss: 0.2186\n","Epoch 150/150\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7872 - loss: 0.2526 - val_accuracy: 0.8333 - val_loss: 0.2179\n"]}]},{"cell_type":"markdown","source":["# Export the weights\n","\n","prints the weights. They should be copy-paste into `model_data.cpp`."],"metadata":{"id":"Ihc7eUI7B-FI"}},{"cell_type":"code","source":["W1, b1 = model.layers[0].get_weights()\n","W2, b2 = model.layers[1].get_weights()\n","W3, b3 = model.layers[2].get_weights()\n","\n","print(W1.shape, b1.shape)\n","print(W2.shape, b2.shape)\n","print(W3.shape, b3.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97kuootTyXOY","executionInfo":{"status":"ok","timestamp":1764946843764,"user_tz":0,"elapsed":51,"user":{"displayName":"Marcelina Marjankowska","userId":"02060429220160125721"}},"outputId":"a11ef83c-bdcb-4c11-9d2d-f2e1ffdf0485"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 16) (16,)\n","(16, 16) (16,)\n","(16, 1) (1,)\n"]}]},{"cell_type":"code","source":["names = [\"W1_data\", \"b1_data\", \"W2_data\", \"b2_data\", \"W3_data\", \"b3_data\"]\n","arrays = [W1, b1, W2.T, b2, W3, b3]\n","\n","for name, array in zip(names, arrays):\n","    print(\"const float %s[] PROGMEM = {\" % name)\n","    print(\"   \", \", \".join([str(x) + \"f\" for x in array.flatten()]))\n","    print(\"};\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-uc4GVTB_2s","executionInfo":{"status":"ok","timestamp":1764946880872,"user_tz":0,"elapsed":31,"user":{"displayName":"Marcelina Marjankowska","userId":"02060429220160125721"}},"outputId":"078fc723-8a3f-41e4-eb88-0db9bc20e9cf"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["const float W1_data[] PROGMEM = {\n","    0.27409142f, 0.3826909f, -0.17235088f, -0.0062267566f, -0.5071732f, 0.07571536f, -0.15021837f, -0.5307514f, 0.3739223f, -0.34649393f, -0.1394358f, 0.34462327f, -0.6657571f, -0.10238792f, 0.3758955f, 0.13714562f, -0.52910507f, -0.5661353f, 0.08199084f, 0.2454236f, -0.18428886f, -0.30513543f, 0.08945175f, -0.024926841f, -0.2144351f, -0.10203645f, -0.54938877f, -0.26069894f, 0.302022f, 0.2111998f, -0.18960765f, 0.40277827f\n","};\n","\n","const float b1_data[] PROGMEM = {\n","    0.0f, 0.0f, -0.09372084f, 0.06307019f, 0.0f, 0.0f, -0.056597f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, -0.06760476f, 0.076421246f, -0.0682106f, -0.065195836f\n","};\n","\n","const float W2_data[] PROGMEM = {\n","    0.03478521f, 0.0824087f, -0.23810582f, -0.25257498f, -0.3541595f, 0.08849737f, 0.35965452f, -0.112455785f, -0.08202848f, 0.078697175f, 0.16618338f, -0.36017004f, -0.43997663f, 0.20932095f, 0.18213758f, 0.03684915f, -0.19130166f, -0.033019632f, 0.2320772f, -0.28801244f, 0.35989377f, -0.0564259f, -0.36648762f, -0.23947304f, 0.13880149f, -0.30138978f, 0.19426224f, 0.1464698f, 0.28860164f, 0.11824991f, 0.24849384f, 0.12339481f, -0.25479114f, -0.066030174f, -0.44366184f, 0.28088772f, 0.032058895f, 0.051609635f, 0.15051533f, 0.3978835f, -0.3799376f, -0.28965157f, -0.42637572f, 0.36745533f, -0.37039995f, -0.11384429f, -0.08516978f, -0.11036552f, 0.049906403f, 0.3829988f, 0.063814044f, -0.017430335f, -0.37347364f, 0.22795889f, -0.31768048f, 0.24061021f, 0.08647969f, 0.06757876f, -0.021797925f, -0.33399945f, -0.4309216f, -0.19343641f, -0.29442182f, -0.10629907f, 0.027190894f, 0.2735525f, -0.20419963f, -0.36162457f, -0.1881216f, 0.32525453f, -0.34655952f, -0.3684221f, 0.23211709f, -0.27852118f, -0.3202255f, 0.01637587f, 0.3126215f, 0.16376057f, 0.13572404f, -0.43122193f, -0.07867995f, -0.04543093f, 0.02434948f, -0.42635155f, 0.37664327f, -0.14759913f, -0.24472302f, -0.0018060505f, -0.37126124f, -0.42939842f, 0.231397f, 0.13569298f, -0.42447323f, 0.15944585f, 0.1273571f, 0.08374938f, 0.10868421f, -0.037582874f, -0.2091393f, -0.2852389f, 0.049842805f, -0.02938214f, 0.4422506f, 0.39191976f, 0.4062647f, -0.32568163f, -0.063507944f, 0.10562739f, 0.13832535f, 0.15092584f, 0.22449896f, 0.14173396f, -0.3110528f, -0.4236783f, 0.06731054f, 0.13297263f, 0.36212918f, 0.29584798f, -0.002032131f, -0.020593673f, 0.20318398f, -0.3536676f, -0.32118738f, 0.34167054f, 0.26970378f, -0.2961814f, -0.0026586056f, -0.22217691f, -0.19607663f, -0.18837433f, -0.39273047f, -0.39327854f, -0.1891451f, -0.10348678f, 0.40118328f, -0.29382697f, 0.21519634f, -0.13846543f, 0.33607152f, -0.19949691f, 0.19735596f, -0.073569864f, 0.07120231f, -0.21101087f, 0.18076286f, 0.37086913f, -0.33331677f, 0.21880901f, 0.41030154f, -0.27356148f, 0.28064424f, 0.22387561f, -0.20134746f, -0.10195193f, 0.16812184f, 0.26491144f, 0.3178532f, 0.21211712f, 0.042899936f, -0.3722046f, 0.2056559f, -0.06782311f, 0.031627823f, -0.25080058f, 0.4160193f, 0.05356279f, 0.25172517f, -0.039527148f, 0.005653858f, -0.04572475f, 0.3585976f, -0.057127923f, 0.37936068f, 0.31449005f, 0.33760372f, 0.06459093f, 0.4033194f, 0.3329622f, 0.018880293f, -0.28430176f, -0.1518091f, -0.19549179f, 0.0074723745f, 0.049622804f, -0.090023786f, 0.15625969f, 0.027420074f, 0.2899761f, -0.2506489f, 0.26274508f, 0.13774857f, 0.18495497f, 0.068217486f, -0.17536736f, 0.023425698f, 0.3219528f, 0.14499876f, -0.38396376f, -0.4117579f, -0.34996772f, 0.27122614f, -0.25275505f, -0.14539418f, -0.26663893f, -0.24054435f, 0.26737037f, -0.4291844f, -0.39545533f, 0.2376279f, 0.34177765f, -0.4162755f, -0.4188118f, 0.34934077f, 0.145277f, 0.18670206f, 0.17585751f, -0.39755592f, 0.16874757f, 0.41157308f, -0.16574109f, -0.1377694f, -0.39674997f, -0.088842124f, 0.32609499f, 0.35862073f, 0.10372195f, 0.069686025f, 0.19711736f, -0.3209329f, -0.40469587f, 0.01697433f, 0.0452514f, -0.21778257f, 0.34401396f, 0.141942f, 0.17433992f, -0.0017323494f, 0.09770504f, -0.31750217f, -0.34739378f, 0.09243396f, 0.26978806f, 0.3600518f, 0.33224156f, -0.41245136f, -0.26059115f, 0.07754571f, 0.368382f, -0.19452548f, 0.0009213984f, -0.11300367f, 0.1284819f, 0.14936842f, -0.40317634f, 0.17031817f, -0.031392645f\n","};\n","\n","const float b2_data[] PROGMEM = {\n","    -0.050527725f, -0.0919805f, -0.070855975f, 0.0f, 0.0f, 0.0f, 0.100475475f, 0.0f, 0.0f, -0.045586646f, -0.096364364f, -0.006065646f, 0.0f, -0.070068926f, 0.0f, -0.08962895f\n","};\n","\n","const float W3_data[] PROGMEM = {\n","    0.19025949f, 0.14592037f, 0.0855212f, 0.5812572f, 0.04303658f, -0.11459172f, -0.010611909f, -0.2715659f, -0.033328176f, -0.4721329f, 0.25216708f, -0.038515747f, 0.57804716f, 0.2380067f, -0.33519903f, 0.34082863f\n","};\n","\n","const float b3_data[] PROGMEM = {\n","    -0.10121559f\n","};\n","\n"]}]}]}